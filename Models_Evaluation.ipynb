{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKBwzJs/BGi+hrM14y44pr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rama-Has/Poem_Generator_Rama_Hasiba_12010022/blob/main/Models_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.28.0 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8X6GTA5ykfF",
        "outputId": "5f7c3018-9a8d-4f27-e651-f9b2c99c6d0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline"
      ],
      "metadata": {
        "id": "9zl453_hp4AV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load models"
      ],
      "metadata": {
        "id": "RK6aXT6LrxOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load aragpt model"
      ],
      "metadata": {
        "id": "Kgjqu6cXr1sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/aragpt_final_one (1).zip\" -d \"/content/\"\n",
        "\n",
        "aragpt_folder_path = '/content/aragpt_model'\n",
        "!mkdir -p \"$folder_path\"\n"
      ],
      "metadata": {
        "id": "42gTvQmQrzaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aragpt_tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "    'aubmindlab/aragpt2-base'\n",
        "    )\n",
        "aragpt_model = GPT2LMHeadModel.from_pretrained(\n",
        "    aragpt_folder_path, \n",
        "    pad_token_id = gpt_tokenizer.eos_token_id\n",
        "    )  "
      ],
      "metadata": {
        "id": "NN1oMEoCsci4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aragpt_generator_ = pipeline(\n",
        "    'text-generation', \n",
        "    model = aragpt_folder_path, \n",
        "    tokenizer='aubmindlab/aragpt2-base'\n",
        "    )"
      ],
      "metadata": {
        "id": "322ZjRbotXTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the gpt model"
      ],
      "metadata": {
        "id": "GCEb4YYqr5vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/gpt_for_poems (2).zip\" -d \"/content/\"\n",
        "\n",
        "folder_path = '/content/gpt_model'\n",
        "!mkdir -p \"$folder_path\""
      ],
      "metadata": {
        "id": "71K762sjrzUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt_model = GPT2LMHeadModel.from_pretrained(\n",
        "    folder_path, \n",
        "    pad_token_id = gpt_tokenizer.eos_token_id\n",
        "    )"
      ],
      "metadata": {
        "id": "j4BDpS5uwDrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_generator = pipeline(\n",
        "    'text-generation', \n",
        "    model = folder_path, \n",
        "    tokenizer = gpt_tokenizer\n",
        "    )"
      ],
      "metadata": {
        "id": "foHZaSzOwTyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the \"Uneversal Sentence Encoder (USE)\" model for embedding."
      ],
      "metadata": {
        "id": "2UAhdISzvZRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pre-trained model#\n",
        "embed = hub.load(\n",
        "    \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
        "    )"
      ],
      "metadata": {
        "id": "9SPk7oNvvY7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define some usefull functions"
      ],
      "metadata": {
        "id": "C-wWhQwWw2eD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku8Y0u_ohY-c"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(embed1, embed2):\n",
        "    # Define two vectors\n",
        "    vector1 = np.array(embed1)\n",
        "    vector2 = np.array(embed2)\n",
        "\n",
        "    # Reshape the vectors to have a 2D shape\n",
        "    vector1 = vector1.reshape(1, -1)\n",
        "    vector2 = vector2.reshape(1, -1)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity(vector1, vector2)\n",
        "\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding_for_prediction(seed_line, generator_): \n",
        "    \n",
        "    #Generate text based on a line\n",
        "    predicted_line = generator_(seed_line, max_length = 60)[0]['generated_text'] \n",
        "    predicted_embedding = embed( [predicted_line] ) \n",
        "    \n",
        "    return [predicted_embedding]"
      ],
      "metadata": {
        "id": "gJZ4goRTuC0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding_for_arabbic_prediction(seed_line: str):\n",
        "    return generate_embedding_for_prediction(seed_line, aragpt_generator_)\n",
        "\n",
        "def generate_embedding_for_english_prediction(seed_line: str):\n",
        "    return generate_embedding_for_prediction(seed_line, english_generator)"
      ],
      "metadata": {
        "id": "fCVC1ExZw8ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the English one."
      ],
      "metadata": {
        "id": "lTK6aMTGtPMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get embedding for the verses in the test dataset because each one except the first one will be the ground truth prediction for the verses before it."
      ],
      "metadata": {
        "id": "eP8PhW6TrOWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the test data"
      ],
      "metadata": {
        "id": "3v8ID_N6v4Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "with open('test_dataset.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Create a DataFrame with each row as a sample\n",
        "df = pd.DataFrame({'text': lines})\n",
        "\n",
        "\n",
        "df['text'] = df['text'].astype(str) \n",
        "\n",
        "# Remove empty rows  \n",
        "df = df[df['text'] != '']\n",
        "\n",
        "df = df.head(150)"
      ],
      "metadata": {
        "id": "2Xxv9Q6dv7G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get embeddings for the ground truth"
      ],
      "metadata": {
        "id": "M8gO-q7Bvuwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_embeddings = embed(\n",
        "    df['text'].to_list()\n",
        ")"
      ],
      "metadata": {
        "id": "W7nia0V8vzDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embeddings'] = [embedded_sentence for embedded_sentence in english_embeddings]"
      ],
      "metadata": {
        "id": "2Yu2irsd76Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-UMffu5979nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get embeddings for the predicted text"
      ],
      "metadata": {
        "id": "eHq67LecrA1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['predicted_embedding'] = df['text'].map(generate_embedding_for_english_prediction)"
      ],
      "metadata": {
        "id": "RzV9v7SAq8eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "FUTpjmXK7-aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the cosine similiraty between embeddings.\n"
      ],
      "metadata": {
        "id": "sD2ESNDop1Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['similarity'] = [i-i for i in range(df.shape[0])]\n",
        "df = df[df['predicted_embedding'].notna()]\n",
        "df.shape[0]\n"
      ],
      "metadata": {
        "id": "pY_Xf7h3p26l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, df.shape[0] - 1): \n",
        "    predicted_embedding = df['predicted_embedding'].iloc[i][0]\n",
        "    ground_truth_embedding = df['predicted_embedding'].iloc[i + 1][0]\n",
        "\n",
        "    df['similarity'].iloc[i] = calculate_similarity(predicted_embedding, ground_truth_embedding)\n"
      ],
      "metadata": {
        "id": "uKK_gLAZp1yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### get some stats about similarities between the ground truth with the predicted embeddings."
      ],
      "metadata": {
        "id": "Po6Ee2BB8DXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['similarity'].describe()"
      ],
      "metadata": {
        "id": "syAG8yGYqQQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    generator_(\n",
        "        'dark storms his genial powers controul\\n', \n",
        "        max_length = 50\n",
        "        )[0]['generated_text'] \n",
        "      )"
      ],
      "metadata": {
        "id": "oCiQgWpdqbOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Enhancement:\n",
        "  1. fine-tune the model on more data.\n",
        "  2. Increase number of epochs during the tunning process."
      ],
      "metadata": {
        "id": "FYv8oGXjqUC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Arabic one."
      ],
      "metadata": {
        "id": "Sd2zet7dtT7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\n",
        "    aragpt_generator_(\n",
        "        'لا  قلت شعرا ولا سمعت غنا ولا', \n",
        "        max_length = 60)[0]['generated_text']\n",
        "      )"
      ],
      "metadata": {
        "id": "3Q5N05-Tu0ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the test data"
      ],
      "metadata": {
        "id": "9c6K8k0ZvO8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "with open('test_dataset.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Create a DataFrame with each row as a sample\n",
        "df = pd.DataFrame({'text': lines})\n",
        "\n",
        "\n",
        "df['text'] = df['text'].astype(str) \n",
        "\n",
        "# Remove empty rows  \n",
        "df = df[df['text'] != '']\n"
      ],
      "metadata": {
        "id": "XvH3vR91tnrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_embedding_for_arabbic_prediction"
      ],
      "metadata": {
        "id": "ERQp__-tx4JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embeddings'] = [embedded_sentence for embedded_sentence in embeddings]\n",
        "df['predicted_embedding'] = [i-i for i in range(df.shape[0])]\n"
      ],
      "metadata": {
        "id": "MSi--fXhx7g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(150):\n",
        "    df['predicted_embedding'].iloc[i + 1] = generate_embedding_for_arabbic_prediction(df['text'].iloc[i])"
      ],
      "metadata": {
        "id": "izZ_Qvvdx9nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(150).copy()\n",
        "df"
      ],
      "metadata": {
        "id": "EqEnycLax_2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding similarity between the textual embedding."
      ],
      "metadata": {
        "id": "Q684SooCtpUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['similarity'] = [i-i for i in range(df.shape[0])]\n",
        "df = df[df['predicted_embedding'].notna()]"
      ],
      "metadata": {
        "id": "jzklE5hTyBWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 150): \n",
        "    predicted_embedding = df['predicted_embedding'].iloc[i][0]\n",
        "    ground_truth_embedding = df['predicted_embedding'].iloc[i + 1][0]\n",
        "\n",
        "    df['similarity'].iloc[i] = calculate_similarity(predicted_embedding, ground_truth_embedding)"
      ],
      "metadata": {
        "id": "UmK2npDbyDkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "w4d_Jqj3yLxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['similarity'].describe()"
      ],
      "metadata": {
        "id": "t0gQiIUAyTtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing this result with results I had from the english transformer, Aragpt-2 performed better than it.**"
      ],
      "metadata": {
        "id": "EaYKPQoFyWbP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCtLO_iQyXSp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}